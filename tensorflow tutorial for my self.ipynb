{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017d2144-026f-4ae7-b63e-be6dca0ccc40",
   "metadata": {},
   "source": [
    "# 1. Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd5e05-1879-4721-9aff-2c43acd8ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f68ec-0463-458f-82c9-c1359c8c075a",
   "metadata": {},
   "source": [
    "# 2. Create Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4d014-f588-4808-b332-6897824c572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a constant tensor\n",
    "tensor_const = tf.constant([1, 2, 3])\n",
    "\n",
    "# Create a variable tensor\n",
    "tensor_var = tf.Variable([4, 5, 6])\n",
    "\n",
    "# Create a placeholder (for input data)\n",
    "tensor_placeholder = tf.placeholder(tf.float32, shape=(None, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe4fd6-292c-44d9-889f-d41aa0fed593",
   "metadata": {},
   "source": [
    "# 3. Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248de6e6-dcb8-40bc-9964-14aee1a8c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise addition\n",
    "result_add = tensor_const + tensor_var\n",
    "\n",
    "# Element-wise multiplication\n",
    "result_mul = tf.multiply(tensor_const, tensor_var)\n",
    "\n",
    "# Matrix multiplication\n",
    "result_matmul = tf.matmul(tensor_const, tf.transpose(tensor_var))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfafa7e-388e-4317-a704-4c13fe677c74",
   "metadata": {},
   "source": [
    "# 4. Session (Eager Execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5e068-3961-4eb9-825c-e7b5c4f39d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable eager execution (not required in TensorFlow 2.x by default)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Run operations eagerly\n",
    "result = result_add.numpy()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c23bce-d106-4b8e-b247-51ef22adc623",
   "metadata": {},
   "source": [
    "# 5. Gradient Tape (for Automatic Differentiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8f9f2-1261-4954-a18b-0000606a8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of automatic differentiation using GradientTape\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(tensor_var)\n",
    "    result = tf.reduce_sum(tf.square(tensor_var))\n",
    "\n",
    "# Calculate gradient\n",
    "gradient = tape.gradient(result, tensor_var)\n",
    "print(gradient.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3d684-3518-442a-a4ff-0667f11560de",
   "metadata": {},
   "source": [
    "# 6. Custom Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b3361-0e75-4d9f-8984-cb1602138db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom operation\n",
    "@tf.function\n",
    "def custom_operation(x):\n",
    "    return tf.square(x) + 3 * x + 2\n",
    "\n",
    "# Use the custom operation\n",
    "result_custom = custom_operation(tensor_var)\n",
    "print(result_custom.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8f14b-76bd-485c-b652-81470a6ed9cc",
   "metadata": {},
   "source": [
    "# 7. Optimizers and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae14816-a861-4cc6-bb7e-c92a20fc06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizer (e.g., Gradient Descent)\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Training loop example\n",
    "for _ in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute loss\n",
    "        loss = compute_loss()\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e5d46-38f0-4697-be1d-df708682157f",
   "metadata": {},
   "source": [
    "# 8. Saving and Restoring Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb6eb0-b67b-4bba-9b19-fd4b0de87dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variables\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.save(\"model_checkpoint.ckpt\")\n",
    "\n",
    "# Restore variables\n",
    "checkpoint.restore(\"model_checkpoint.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9adb866-686f-4d08-b84f-914735604a18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa636b91-efb4-4f19-9956-bcd7b8d1adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2feacd9-991b-4e27-a5a2-daa6df649c8a",
   "metadata": {},
   "source": [
    "# Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb7f6d5-ad48-47b2-84af-6ddc7f452f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_const = tf.constant([1, 2, 3]) # One dimension will not work with tf.matmul it must be at least 2 dimension\n",
    "tensor_var = tf.Variable([4, 5, 6])   # One dimension will not work with tf.matmul it must be at least 2 dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0dfeb4f-45c5-4d5e-9109-32644568c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_const = tf.constant([[1, 2, 3]]) # 2 dimension or above will work with tf.matmul\n",
    "tensor_var = tf.Variable([[4, 5, 6]])   # 2 dimension or above will work with tf.matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a75fe-6fd1-42a7-8be1-d091368d3d57",
   "metadata": {},
   "source": [
    "# Basic Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59669e-4a94-43fc-9a33-bddcb17beabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor bitwise addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecd16070-df39-404c-9f17-ed22d2e1fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_add = tensor_const + tensor_var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4b8392e-c4bb-4c0b-9088-efc15960c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5 7 9]], shape=(1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(result_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395c89a-3fd4-481b-ad3a-d09b4a97ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor bitwise subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0d44f09-6b00-4f20-b82b-058aa510281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sub = tensor_const - tensor_var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93b1d567-8db0-4886-abde-add5571eae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-3 -3 -3]], shape=(1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(result_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a18492-2867-40cb-a1b5-63a34b4acb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor bitwise division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f852393a-2a5f-44e4-b328-8fcd9b4c09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_div = tensor_const / tensor_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "461cd483-b992-404b-9334-0b8c42967ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.25 0.4  0.5 ]], shape=(1, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(result_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3902cd1-aab8-4043-bae1-0a0134f384ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor bitwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7828a5d-2745-46fa-9b45-61e96e168b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mul = tf.multiply(tensor_const, tensor_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08bfbbd6-dae3-4db2-8306-2cc93aad37b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 4 10 18]], shape=(1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(result_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4b911a4-c90d-4d1e-93d6-63b933a32fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c49a08c-ca54-4e3f-be26-d5c9c3f9295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matmul = tf.matmul(tensor_const, tf.transpose(tensor_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "815d6ab2-06cc-4d22-8972-189af5ddbb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[32]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(result_matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df991df-d483-4ad9-818c-23bea713e54d",
   "metadata": {},
   "source": [
    "# Convert NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26eab606-fbca-41ad-b2fa-9c5b339d1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "tensor_from_numpy = tf.convert_to_tensor(numpy_array, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b897ec2-ff60-40c6-9a18-20df19ffeaad",
   "metadata": {},
   "source": [
    "# Convert Pandas DataFrame to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c1fd6b-820a-45a5-ac4a-2a7306cbb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1': [1, 2, 3], 'col2': [4, 5, 6], 'col3': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "tensor_from_dataframe = tf.constant(df.values, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce9c5f6-8f7e-412b-8bac-8b0a40dfdc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 4. 7.]\n",
      " [2. 5. 8.]\n",
      " [3. 6. 9.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_from_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edde1b-f1e4-4bf1-b719-4f09fb3fcc10",
   "metadata": {},
   "source": [
    "# Convert Images to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e98632-35ce-4c67-bde7-eb50b9c8e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_path = 'image.PNG'\n",
    "image = Image.open(image_path)\n",
    "image_array = np.array(image)\n",
    "tensor_from_image = tf.convert_to_tensor(image_array, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cfac0-bf05-4160-8004-422760422c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dec4513-b3db-4f31-b47f-d69b21eb9996",
   "metadata": {},
   "source": [
    "# Generating computational graph to use it later in finding the gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2f131-7e43-432d-a062-a4cbcd37311c",
   "metadata": {},
   "source": [
    "In TensorFlow, the tf.GradientTape is used to compute the gradient of a computation with respect to its input variables. By default, the tf.GradientTape automatically watches any trainable variables, meaning that you don't need to explicitly use watch for variables that are trainable (like variables created with tf.Variable). However, if you are working with constant tensors or non-trainable variables, you need to explicitly specify that you want to watch them using watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd8b64-a9a6-47c2-80c6-cafa5f305195",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "  g.watch(x)\n",
    "  y = x * x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecca56-9462-4fdd-a27f-91699bae51c5",
   "metadata": {},
   "source": [
    "Here, x is a constant tensor, and by default, it is not watched by the gradient tape. However, you want to compute the gradient of y with respect to x. Therefore, you use g.watch(x) to explicitly tell the gradient tape to watch the constant tensor x. This allows TensorFlow to compute the gradient of y with respect to x during the gradient tape's scope.\n",
    "\n",
    "If x were a trainable variable created with tf.Variable, you wouldn't need to use g.watch(x) because tf.GradientTape automatically watches trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57caf60-488a-475f-b22d-9cb6ee7d8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "  y = x * x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97795291-6512-4b44-b494-c71e73d74948",
   "metadata": {},
   "source": [
    "In this case, x is a trainable variable, and TensorFlow automatically watches it without the need for explicit watch statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355f1dd-8891-46be-a3a4-9a8f7dd7e8d7",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb0406bd-2459-4abb-b186-c061b4272052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Some example variables\n",
    "w0 = tf.Variable(1.0, trainable=True)\n",
    "w1 = tf.Variable(2.0, trainable=True)\n",
    "w2 = tf.Variable(3.0, trainable=True)\n",
    "w3 = tf.Variable(4.0, trainable=True)\n",
    "w4 = tf.Variable(5.0, trainable=True)\n",
    "\n",
    "# Example equation using the variables\n",
    "def equation(w0, w1, w2, w3, w4, x):\n",
    "    return w0 * x**4 + w1 * x**3 + w2 * x**2 + w3 * x + w4\n",
    "\n",
    "# Example input\n",
    "x_input = tf.constant(2.0)\n",
    "\n",
    "# Use tf.GradientTape to compute gradients\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    # Watch the variables\n",
    "    tape.watch(w0)\n",
    "    tape.watch(w1)\n",
    "    tape.watch(w2)\n",
    "    tape.watch(w3)\n",
    "    tape.watch(w4)\n",
    "\n",
    "    # Compute the output of the equation\n",
    "    y = equation(w0, w1, w2, w3, w4, x_input)\n",
    "\n",
    "# Compute gradients with respect to each variable\n",
    "grad_w0 = tape.gradient(y, w0)\n",
    "grad_w1 = tape.gradient(y, w1)\n",
    "grad_w2 = tape.gradient(y, w2)\n",
    "grad_w3 = tape.gradient(y, w3)\n",
    "grad_w4 = tape.gradient(y, w4)\n",
    "\n",
    "# Update the variables (you can use any optimizer here)\n",
    "learning_rate = 0.01\n",
    "w0.assign_sub(learning_rate * grad_w0)\n",
    "w1.assign_sub(learning_rate * grad_w1)\n",
    "w2.assign_sub(learning_rate * grad_w2)\n",
    "w3.assign_sub(learning_rate * grad_w3)\n",
    "w4.assign_sub(learning_rate * grad_w4)\n",
    "\n",
    "# Clean up resources used by the tape\n",
    "del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad4a4f7c-3057-4720-ae5a-185f2b5b5bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.84000003>\n",
      "w1= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.92>\n",
      "w2= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.96>\n",
      "w3= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.98>\n",
      "w4= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.99>\n"
     ]
    }
   ],
   "source": [
    "print('w0=',w0)\n",
    "print('w1=',w1)\n",
    "print('w2=',w2)\n",
    "print('w3=',w3)\n",
    "print('w4=',w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ec36b-001c-48f2-813f-a9da4abd04de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94225440-8b16-4101-8b4e-9c5f954d6bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 5.873963832855225\n",
      "Epoch 20/100, Loss: 3.4179155826568604\n",
      "Epoch 30/100, Loss: 2.4156360626220703\n",
      "Epoch 40/100, Loss: 1.986089825630188\n",
      "Epoch 50/100, Loss: 1.782915472984314\n",
      "Epoch 60/100, Loss: 1.6699206829071045\n",
      "Epoch 70/100, Loss: 1.5935282707214355\n",
      "Epoch 80/100, Loss: 1.5326367616653442\n",
      "Epoch 90/100, Loss: 1.4789106845855713\n",
      "Epoch 100/100, Loss: 1.4290356636047363\n",
      "Final Trainable Variables:\n",
      "Variable:0: 0.6443644165992737\n",
      "Variable:0: 0.6227445006370544\n",
      "Variable:0: 2.3087642192840576\n",
      "Variable:0: 3.41403865814209\n",
      "Variable:0: 3.827744960784912\n",
      "Variable:0: -0.028387809172272682\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple model with trainable variables\n",
    "class LinearRegressionModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.w0 = tf.Variable(1.0, trainable=True)\n",
    "        self.w1 = tf.Variable(2.0, trainable=True)\n",
    "        self.w2 = tf.Variable(3.0, trainable=True)\n",
    "        self.w3 = tf.Variable(4.0, trainable=True)\n",
    "        self.w4 = tf.Variable(5.0, trainable=True)\n",
    "        self.w5 = tf.Variable(0.5, trainable=True)  # Additional trainable variable\n",
    "        \n",
    "\n",
    "    def equation(self, x):\n",
    "        # Multiple-input linear regression equation\n",
    "        return self.w0 * x[:, 0] + self.w1 * x[:, 1] + self.w2 * x[:, 2] + self.w3 * x[:, 3] + self.w4 + self.w5 * x[:, 4] \n",
    "\n",
    "# Generate some random data for demonstration\n",
    "np.random.seed(0)\n",
    "data_points = np.random.rand(100, 6)  # 100 samples, 6 features\n",
    "\n",
    "# Create input data and labels\n",
    "x_train = data_points[:, :5]\n",
    "y_train = 2 * x_train[:, 0] - 3 * x_train[:, 1] + 1.5 * x_train[:, 2] + 4 * x_train[:, 3] + 5 + 0.5 * x_train[:, 4] + np.random.normal(0, 0.1, size=(100,))\n",
    "\n",
    "# Convert data to TensorFlow tensors\n",
    "x_train_tensor = tf.constant(x_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Define the loss function (mean squared error)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute predictions\n",
    "        predictions = model.equation(x_train_tensor)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        loss = mean_squared_error(y_train_tensor, predictions)\n",
    "\n",
    "    # Compute gradients with respect to trainable variables\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Update the trainable variables using the gradients and the learning rate\n",
    "    for var, grad in zip(model.trainable_variables, gradients):\n",
    "        var.assign_sub(learning_rate * grad)\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Print the final values of the trainable variables\n",
    "print(\"Final Trainable Variables:\")\n",
    "for var in model.trainable_variables:\n",
    "    print(f\"{var.name}: {var.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc3e72-c17e-4800-b8b9-c4d4d405f120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c30e55d-64e8-49b5-9b2f-eede15543ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 9.301063537597656\n",
      "Epoch 20/100, Loss: 7.546630859375\n",
      "Epoch 30/100, Loss: 6.092097759246826\n",
      "Epoch 40/100, Loss: 4.928334712982178\n",
      "Epoch 50/100, Loss: 4.027708530426025\n",
      "Epoch 60/100, Loss: 3.352130651473999\n",
      "Epoch 70/100, Loss: 2.859957218170166\n",
      "Epoch 80/100, Loss: 2.5107738971710205\n",
      "Epoch 90/100, Loss: 2.268342971801758\n",
      "Epoch 100/100, Loss: 2.102170944213867\n",
      "Final Trainable Variables:\n",
      "Variable:0: 0.33037829399108887\n",
      "Variable:0: 1.1997393369674683\n",
      "Variable:0: 2.2734334468841553\n",
      "Variable:0: 3.2785892486572266\n",
      "Variable:0: 4.278080463409424\n",
      "Variable:0: -0.20118720829486847\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple model with trainable variables\n",
    "class LinearRegressionModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.w0 = tf.Variable(1.0, trainable=True)\n",
    "        self.w1 = tf.Variable(2.0, trainable=True)\n",
    "        self.w2 = tf.Variable(3.0, trainable=True)\n",
    "        self.w3 = tf.Variable(4.0, trainable=True)\n",
    "        self.w4 = tf.Variable(5.0, trainable=True)\n",
    "        self.w5 = tf.Variable(0.5, trainable=True)  # Additional trainable variable\n",
    "      \n",
    "\n",
    "    def equation(self, x):\n",
    "        # Multiple-input linear regression equation\n",
    "        return self.w0 * x[:, 0] + self.w1 * x[:, 1] + self.w2 * x[:, 2] + self.w3 * x[:, 3] + self.w4 + self.w5 * x[:, 4] \n",
    "\n",
    "# Generate some random data for demonstration\n",
    "np.random.seed(0)\n",
    "data_points = np.random.rand(100, 6)  # 100 samples, 6 features\n",
    "\n",
    "# Create input data and labels\n",
    "x_train = data_points[:, :5]\n",
    "y_train = 2 * x_train[:, 0] - 3 * x_train[:, 1] + 1.5 * x_train[:, 2] + 4 * x_train[:, 3] + 5 + 0.5 * x_train[:, 4] + np.random.normal(0, 0.1, size=(100,))\n",
    "\n",
    "# Convert data to TensorFlow tensors\n",
    "x_train_tensor = tf.constant(x_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Create an optimizer (Adam optimizer in this case)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define the loss function (mean squared error)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Training loop with Adam optimizer\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute predictions\n",
    "        predictions = model.equation(x_train_tensor)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        loss = mean_squared_error(y_train_tensor, predictions)\n",
    "\n",
    "    # Compute gradients with respect to trainable variables\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Update the trainable variables using the Adam optimizer\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Print the final values of the trainable variables\n",
    "print(\"Final Trainable Variables:\")\n",
    "for var in model.trainable_variables:\n",
    "    print(f\"{var.name}: {var.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f6816-8661-422a-936f-cf037fae86b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc17fbb6-8711-4bf9-ba2b-59eecd29d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 4.227802753448486\n",
      "Epoch 20/100, Loss: 4.03024435043335\n",
      "Epoch 30/100, Loss: 3.8759665489196777\n",
      "Epoch 40/100, Loss: 3.742917537689209\n",
      "Epoch 50/100, Loss: 3.6180503368377686\n",
      "Epoch 60/100, Loss: 3.499094247817993\n",
      "Epoch 70/100, Loss: 3.3861138820648193\n",
      "Epoch 80/100, Loss: 3.2786853313446045\n",
      "Epoch 90/100, Loss: 3.1765518188476562\n",
      "Epoch 100/100, Loss: 3.0796473026275635\n",
      "Final Trainable Variables (Weights):\n",
      "[[2.0219421 1.1459466 2.888826  3.994519  4.177248 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple model with trainable variables as a vector\n",
    "class LinearRegressionModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        # Represent the variables as a single vector\n",
    "        self.weights = tf.Variable([[1.0, 2.0, 3.0, 4.0, 5.0]], trainable=True)\n",
    "\n",
    "    def equation(self, x):\n",
    "        # Multiple-input linear regression equation using matrix multiplication\n",
    "        return tf.reduce_sum(self.weights * x, axis=1)\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "np.random.seed(0)\n",
    "data_points = np.random.rand(100, 6)  # 100 samples, 6 features\n",
    "\n",
    "# Create input data and labels\n",
    "x_train = data_points[:, :5]\n",
    "y_train = 2 * x_train[:, 0] - 3 * x_train[:, 1] + 1.5 * x_train[:, 2] + 4 * x_train[:, 3] + 5 + 0.5 * x_train[:, 4] + np.random.normal(0, 0.1, size=(100,))\n",
    "\n",
    "# Convert data to TensorFlow tensors\n",
    "x_train_tensor = tf.constant(x_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Create an optimizer (Adam optimizer in this case)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define the loss function (mean squared error)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Training loop with Adam optimizer\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute predictions\n",
    "        predictions = model.equation(x_train_tensor)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        loss = mean_squared_error(y_train_tensor, predictions)\n",
    "\n",
    "    # Compute gradients with respect to trainable variables\n",
    "    gradients = tape.gradient(loss, [model.weights])\n",
    "\n",
    "    # Update the trainable variables using the Adam optimizer\n",
    "    optimizer.apply_gradients(zip(gradients, [model.weights]))\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Print the final values of the trainable variables (weights)\n",
    "print(\"Final Trainable Variables (Weights):\")\n",
    "print(model.weights.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d6c21-fc79-4ffb-963d-014ebcc6e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
